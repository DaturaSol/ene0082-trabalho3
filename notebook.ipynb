{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9472af",
   "metadata": {},
   "source": [
    "# Trabalho Computacional 3. Rede Convolucional e Transfer Learning\n",
    "\n",
    "> **Nome**: *Gabriel Martins Silveira de Oliveira*.  \n",
    "> **Matrícula**: 190042656."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c564f9",
   "metadata": {},
   "source": [
    "# Verificação de Hardware\n",
    "\n",
    "Antes de iniciarmos o trabalho, é fundamental definir alguns parâmetros para garantir a execução do notebook com o mínimo de interrupções. Inicialmente, considerou-se o uso da TPU (Tensor Processing Unit) do Google para otimizar os resultados. Contudo, essa opção não se mostrou prática devido à alta demanda e baixa disponibilidade desses recursos, dificultando o acesso.\n",
    "\n",
    "Portanto, optaremos por utilizar apenas CUDA. Não é recomendado executar os experimentos utilizando somente a CPU. Caso esteja utilizando o Google Colab, recomenda-se fortemente o uso da GPU disponibilizada pela plataforma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7436e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making use of CUDA\n",
      "With 4 Workers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "HAS_CUDA = torch.cuda.is_available()\n",
    "NUM_CORES = os.cpu_count()\n",
    "num_workers = NUM_CORES // 2 if NUM_CORES else 0\n",
    "device_type = \"gpu\" if HAS_CUDA else \"cpu\"\n",
    "\n",
    "colab_message = \"Working in Google Colab\\n\" if IN_COLAB else \"\"\n",
    "cuda_message = \"Making use of CUDA\\n\" if HAS_CUDA else \"No CUDA device found\"\n",
    "workers_message = f\"With {num_workers} Workers\"\n",
    "\n",
    "print(colab_message + cuda_message + workers_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d055ff",
   "metadata": {},
   "source": [
    "# Importações Essenciais\n",
    "\n",
    "Recomenda-se a execução deste código no Google Colab. No entanto, caso deseje executá-lo localmente, o arquivo `pyproject.toml` foi disponibilizado para a correta instalação das dependências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "609fb74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google colab dependencies\n",
    "if IN_COLAB:\n",
    "    import subprocess\n",
    "    try:\n",
    "        subprocess.run(\n",
    "                [\"pip\", \"install\", \"pytorch-lightning\", \"torchmetrics\"], check=True\n",
    "            )\n",
    "        print(\"Successfully installed packages.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error installing packages: {e}\")\n",
    "        \n",
    "# PyTorch\n",
    "import torch\n",
    "from torch import nn, optim, Generator\n",
    "from torch.utils.data import random_split, Subset, DataLoader\n",
    "\n",
    "# TorchVision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import (\n",
    "    vgg16, \n",
    "    VGG16_Weights, \n",
    "    inception_v3, \n",
    "    Inception_V3_Weights,\n",
    ")\n",
    "\n",
    "# TorchMetrics\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "# TorchLightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "\n",
    "# Utils\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "from typing import List, Tuple, cast, Literal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83702d1",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Neste trabalho, utilizaremos a base de dados [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "Ela é composta por 60.000 imagens coloridas de 32x32 pixels (3 canais de cor).\n",
    "\n",
    "Inicialmente, as imagens serão mantidas em suas dimensões originais. Esta abordagem permitirá avaliar diferentes configurações preliminares e identificar as mais promissoras no contexto do modelo mais simples. Posteriormente, ao explorar arquiteturas mais complexas, como o VGG16, será realizado o redimensionamento das imagens. Para essa etapa, será aplicado um dos métodos de pré-processamento que apresentou o melhor desempenho com o modelo base. Embora essa estratégia não garanta, necessariamente, um impacto positivo idêntico no novo modelo, espera-se que haja uma correlação positiva, influenciando o processo de ajuste dos pesos da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bbb391",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Dataset:\n",
    "    \"\"\"I did some chances to this class to make it easier to work with\"\"\"\n",
    "    train: Subset[datasets.CIFAR10]\n",
    "    val: Subset[datasets.CIFAR10]\n",
    "    test: datasets.CIFAR10\n",
    "    classes: List[str]\n",
    "    resize: Tuple[int, int]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Path = Path(\"./.data/\"),\n",
    "        resize: Tuple[int, int] = (32, 32),\n",
    "    ):\n",
    "        trans = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(resize),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    (0.5, 0.5, 0.5),\n",
    "                    (0.5, 0.5, 0.5),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.full_train = datasets.CIFAR10(\n",
    "            root=root, train=True, transform=trans, download=True\n",
    "        )\n",
    "\n",
    "        self.classes = self.full_train.classes\n",
    "\n",
    "        train_set_size = int(len(self.full_train) * 0.8)\n",
    "        valid_set_size = len(self.full_train) - train_set_size\n",
    "\n",
    "        seed = Generator().manual_seed(42)\n",
    "        self.train, self.val = random_split(\n",
    "            self.full_train, [train_set_size, valid_set_size], generator=seed\n",
    "        )\n",
    "\n",
    "        self.test = datasets.CIFAR10(\n",
    "            root=root, train=False, transform=trans, download=True\n",
    "        )\n",
    "\n",
    "    def get_dataloader(\n",
    "        self,\n",
    "        dataset_type: Literal[\"train\", \"test\", \"val\"],\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = 2,\n",
    "        shuffle: bool = False,\n",
    "        persistent_workers: bool = True,\n",
    "        pin_memory=True,\n",
    "    ) -> DataLoader:\n",
    "        \n",
    "        dataset: Subset[datasets.CIFAR10] = getattr(self, dataset_type)\n",
    "        if dataset_type == \"train\":\n",
    "            shuffle = True\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            persistent_workers=persistent_workers,\n",
    "            pin_memory=pin_memory,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a8a7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"./.data/\")\n",
    "root.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abdd01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFAR10Dataset(root=root)\n",
    "train_dataloader = dataset.get_dataloader(dataset_type=\"train\", num_workers=num_workers)\n",
    "val_dataloader = dataset.get_dataloader(dataset_type=\"val\", num_workers=num_workers)\n",
    "test_dataloader = dataset.get_dataloader(dataset_type=\"val\", num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ecd3bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40_000\n",
      "Number of validation examples: 10_000\n",
      "Number of test examples: 10_000\n",
      "\n",
      "Number of Classes: 10\n",
      "Classes:\n",
      "  airplane\n",
      "  automobile\n",
      "  bird\n",
      "  cat\n",
      "  deer\n",
      "  dog\n",
      "  frog\n",
      "  horse\n",
      "  ship\n",
      "  truck\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Number of training examples: {len(dataset.train):_}\\n\"\n",
    "    f\"Number of validation examples: {len(dataset.val):_}\\n\"\n",
    "    f\"Number of test examples: {len(dataset.test):_}\\n\\n\"\n",
    "    f\"Number of Classes: {len(dataset.classes):_}\\n\"\n",
    "    \"Classes:\",\n",
    "    *dataset.classes,\n",
    "    sep=\"\\n  \",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e031138",
   "metadata": {},
   "source": [
    "Observa-se que o dataset é composto por 10 classes distintas. A divisão dos dados compreende 40.000 exemplos para treinamento, 10.000 para validação e 10.000 para teste. Abaixo, são apresentados alguns exemplos das imagens contidas neste conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b8280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_batch(\n",
    "    images_batch: torch.Tensor,\n",
    "    labels_batch: torch.Tensor,\n",
    "    class_names: List[str],\n",
    "    mean: float = 0.5,\n",
    "    std: float = 0.5,\n",
    "    num_images_to_show: int = 9,\n",
    "):\n",
    "    images_batch = images_batch.cpu()\n",
    "\n",
    "    axes_grid_array: np.ndarray\n",
    "\n",
    "    _, axes_grid_array = plt.subplots(\n",
    "        3, 3, figsize=(10, 10)\n",
    "    )\n",
    "\n",
    "    axes_flat_array = axes_grid_array.flatten()\n",
    "\n",
    "    for i in range(min(num_images_to_show, len(images_batch))):\n",
    "        ax = axes_flat_array[i]\n",
    "        assert isinstance(ax, Axes), \"Each element should be an Axes object\" # Pylance...\n",
    "\n",
    "        # We need to unnormalize the image ):\n",
    "        img = images_batch[i]\n",
    "        img = img * std + mean\n",
    "        img = img.permute(1, 2, 0)\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        \n",
    "        ax.imshow(img.numpy())\n",
    "        label_index: int = int(labels_batch[i].item())\n",
    "        ax.set_title(f\"Label: {class_names[label_index]}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16e24915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying a batch of training images after transforms:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_iter = iter(test_dataloader)\n",
    "try:\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    print(\"Displaying a batch of training images after transforms:\")\n",
    "    imshow_batch(images, labels, dataset.classes, num_images_to_show=9)\n",
    "\n",
    "except StopIteration:\n",
    "    print(\"DataLoader is empty or could not fetch a batch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8139f66d",
   "metadata": {},
   "source": [
    "# Treinamento de uma MLP Simples\n",
    "\n",
    "Nesta etapa, será realizado o treinamento de uma Rede Perceptron Multicamadas (MLP) básica, composta por duas camadas ocultas. Para otimizar e gerenciar o processo de treinamento, será utilizada a biblioteca `PyTorch Lightning`.\n",
    "\n",
    "Uma rotina de treinamento foi customizada para simplificar a aplicação de técnicas de regularização, como L2, L1 e dropout. Contudo, funcionalidades essenciais da biblioteca `PyTorch Lightning`, como o mecanismo de `EarlyStopping` (parada antecipada) e a classe `Trainer` para a orquestração do ciclo de treinamento, continuarão a ser empregadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b5ed4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHParams(Namespace):\n",
    "    lr: float\n",
    "    num_classes: int\n",
    "    weight_decay: float  # L2 Regularization\n",
    "    l1_strength: float  # L1 Regularization\n",
    "\n",
    "\n",
    "class LightModel(pl.LightningModule):\n",
    "    model: nn.Module\n",
    "    hparams: ModelHParams\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        lr: float = 1e-3,\n",
    "        num_classes: int = 10,\n",
    "        weight_decay: float = 0.0,  # No L2 regularization\n",
    "        l1_strength: float = 0.0,  # No L1 regularization\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor]) -> torch.Tensor:\n",
    "        X, y = batch\n",
    "        y_hat: torch.Tensor = self(X)\n",
    "        cross_entropy_loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        total_loss = cross_entropy_loss\n",
    "\n",
    "        if self.hparams.l1_strength > 0:\n",
    "            total_loss = self._deal_with_l1(total_loss)\n",
    "            \n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            total_loss,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "            sync_dist=True,\n",
    "        )\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def _deal_with_l1(self, total_loss: torch.Tensor) -> torch.Tensor:\n",
    "        l1_penalty = 0.0\n",
    "        for param in self.model.parameters():\n",
    "            if param.requires_grad:\n",
    "                l1_penalty += torch.norm(param, 1)  # L1 norm\n",
    "        total_loss += self.hparams.l1_strength * l1_penalty\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor]) -> torch.Tensor:\n",
    "        X, y = batch\n",
    "        y_hat: torch.Tensor = self(X)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor]):\n",
    "        X, y = batch\n",
    "        y_hat: torch.Tensor = self(X)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        acc = accuracy(\n",
    "            preds,\n",
    "            y,\n",
    "            task=\"multiclass\",\n",
    "            num_classes=self.hparams.get(\"num_classes\", 10),\n",
    "        )\n",
    "        self.log(\"test_acc\", acc, on_epoch=True)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        self.log(\"test_loss\", loss, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self) -> optim.Optimizer:\n",
    "        optimizer = optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db4e659",
   "metadata": {},
   "source": [
    "## Modelo Mais Simples\n",
    "\n",
    "Este modelo inicial representa a configuração mais básica, sem a aplicação de técnicas de regularização L1 ou L2. Como função de ativação nas camadas ocultas, utiliza-se a ReLU. A arquitetura é detalhada no diagrama abaixo:\n",
    "\n",
    "<center>\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    Input[Entrada<br/>Imagem 3x32x32<br/>Vetor de 3072 características] --> Hidden1(1ª Camada Oculta<br/>64 neurônios<br/>Ativação: ReLU);\n",
    "    Hidden1 --> Hidden2(2ª Camada Oculta<br/>16 neurônios<br/>Ativação: ReLU);\n",
    "    Hidden2 --> Output[Camada de Saída<br/>10 classes neurônios]\n",
    "```\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "685f1b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model | Sequential | 197 K  | train\n",
      "---------------------------------------------\n",
      "197 K     Trainable params\n",
      "0         Non-trainable params\n",
      "197 K     Total params\n",
      "0.792     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MLP classifier ---\n",
      "\n",
      "Epoch 12: 100%|██████████| 625/625 [00:07<00:00, 80.22it/s, v_num=54, train_loss_step=1.420, val_loss=1.460, train_loss_epoch=1.130] \n"
     ]
    }
   ],
   "source": [
    "arch = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3 * 32 * 32, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 10),\n",
    ")\n",
    "mlp = LightModel(arch)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5, \n",
    "    mode=\"min\",\n",
    "    min_delta=0.001,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    callbacks=[early_stopping], max_epochs=50, accelerator=device_type, devices=1\n",
    ")\n",
    "print(\"\\n--- Training MLP classifier ---\\n\")\n",
    "trainer.fit(\n",
    "    model=mlp, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d254b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing MPL classifier ---\n",
      "\n",
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 120.63it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.5020999908447266\n",
      "        test_loss           1.4607789516448975\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.5020999908447266, 'test_loss': 1.4607789516448975}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Testing MPL classifier ---\\n\")\n",
    "trainer.test(model=mlp, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9010b22b",
   "metadata": {},
   "source": [
    "**Conclusões sobre o Modelo Simples**\n",
    "\n",
    "A acurácia obtida com o modelo simples situa-se em aproximadamente 50%. Embora este valor possa ser considerado modesto, tal desempenho era, em certa medida, esperado, dada a simplicidade da arquitetura empregada frente à tarefa de classificação.\n",
    "\n",
    "Contudo, alcançar este patamar de acurácia, especialmente ao considerar a complexidade intrínseca das imagens do dataset (CIFAR-10) e sua baixa resolução (32x32 pixels), pode ser interpretado como um resultado inicial promissor. Este desempenho indica que o modelo conseguiu aprender algumas características relevantes dos dados, estabelecendo uma linha de base para futuras otimizações e a exploração de arquiteturas mais elaboradas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f8cc6",
   "metadata": {},
   "source": [
    "## Modelo MLP com Regularização L1\n",
    "\n",
    "Mantendo a mesma arquitetura e os mesmos hiperparâmetros do [modelo mais simples](#modelo-mais-simples), este modelo diferencia-se pela introdução da regularização L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16a087dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model | Sequential | 197 K  | train\n",
      "---------------------------------------------\n",
      "197 K     Trainable params\n",
      "0         Non-trainable params\n",
      "197 K     Total params\n",
      "0.792     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MLP classifier L1 ---\n",
      "\n",
      "Epoch 14: 100%|██████████| 625/625 [00:08<00:00, 73.09it/s, v_num=55, train_loss_step=1.380, val_loss=1.480, train_loss_epoch=1.240]\n"
     ]
    }
   ],
   "source": [
    "arch = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3 * 32 * 32, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 10),\n",
    ")\n",
    "mlp = LightModel(arch, l1_strength=1e-5)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5, \n",
    "    mode=\"min\",\n",
    "    min_delta=0.001,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    callbacks=[early_stopping], max_epochs=50, accelerator=device_type, devices=1\n",
    ")\n",
    "print(\"\\n--- Training MLP classifier L1 ---\\n\")\n",
    "trainer.fit(\n",
    "    model=mlp, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6bbadf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing MPL classifier L1---\n",
      "\n",
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 132.00it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4975999891757965\n",
      "        test_loss           1.4784318208694458\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.4975999891757965, 'test_loss': 1.4784318208694458}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Testing MPL classifier L1---\\n\")\n",
    "trainer.test(model=mlp, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d841758",
   "metadata": {},
   "source": [
    "**Conclusões sobre o Modelo Simples com Regularização L1**\n",
    "\n",
    "Os resultados de acurácia obtidos são praticamente idênticos aos do modelo sem regularização. Contudo, observou-se um período de treinamento mais longo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593db33",
   "metadata": {},
   "source": [
    "## Modelo MLP com Regularização L2\n",
    "\n",
    "Mantendo a mesma arquitetura e os mesmos hiperparâmetros do [modelo mais simples](#modelo-mais-simples), este modelo diferencia-se pela introdução da regularização L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b3dd30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model | Sequential | 197 K  | train\n",
      "---------------------------------------------\n",
      "197 K     Trainable params\n",
      "0         Non-trainable params\n",
      "197 K     Total params\n",
      "0.792     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MLP classifier L2 ---\n",
      "\n",
      "Epoch 13: 100%|██████████| 625/625 [00:08<00:00, 77.24it/s, v_num=56, train_loss_step=1.140, val_loss=1.500, train_loss_epoch=1.120] \n"
     ]
    }
   ],
   "source": [
    "arch = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3 * 32 * 32, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 10),\n",
    ")\n",
    "mlp = LightModel(arch, weight_decay=1e-5)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5, \n",
    "    mode=\"min\",\n",
    "    min_delta=0.001,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    callbacks=[early_stopping], max_epochs=50, accelerator=device_type, devices=1\n",
    ")\n",
    "print(\"\\n--- Training MLP classifier L2 ---\\n\")\n",
    "trainer.fit(\n",
    "    model=mlp, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494dac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing MPL classifier L2---\n",
      "\n",
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 140.48it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4950000047683716\n",
      "        test_loss           1.5034754276275635\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.4950000047683716, 'test_loss': 1.5034754276275635}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Testing MPL classifier L2---\\n\")\n",
    "trainer.test(model=mlp, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393eb352",
   "metadata": {},
   "source": [
    "**Conclusões sobre o Modelo Simples com Regularização L2**\n",
    "\n",
    "Os resultados de acurácia obtidos foram, em geral, consistentes com os dos dois testes precedentes. Tempo de treinamento inalterado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c334d2f",
   "metadata": {},
   "source": [
    "### Experimento com Leaky ReLU\n",
    "\n",
    "\n",
    "<center>\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    Input[Entrada<br/>Imagem 3x32x32<br/>Vetor de 3072 características] --> Hidden1(1ª Camada Oculta<br/>64 neurônios<br/>Ativação: Leaky ReLU);\n",
    "    Hidden1 --> Hidden2(2ª Camada Oculta<br/>16 neurônios<br/>Ativação: Leaky ReLU);\n",
    "    Hidden2 --> Output[Camada de Saída<br/>10 classes neurônios]\n",
    "```\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9df705cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model | Sequential | 197 K  | train\n",
      "---------------------------------------------\n",
      "197 K     Trainable params\n",
      "0         Non-trainable params\n",
      "197 K     Total params\n",
      "0.792     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MLP classifier Leaky ReLU---\n",
      "\n",
      "Epoch 10: 100%|██████████| 625/625 [00:07<00:00, 83.00it/s, v_num=57, train_loss_step=1.140, val_loss=1.430, train_loss_epoch=1.170] \n"
     ]
    }
   ],
   "source": [
    "arch_leaky = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3 * 32 * 32, 64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(64, 16),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(16, 10),\n",
    ")\n",
    "\n",
    "mlp = LightModel(arch_leaky)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5, \n",
    "    mode=\"min\",\n",
    "    min_delta=0.001,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    callbacks=[early_stopping], max_epochs=50, accelerator=device_type, devices=1\n",
    ")\n",
    "print(\"\\n--- Training MLP classifier Leaky ReLU---\\n\")\n",
    "trainer.fit(\n",
    "    model=mlp, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c18b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing MPL classifier Leaky ReLU---\n",
      "\n",
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 137.43it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.5091999769210815\n",
      "        test_loss           1.4291560649871826\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.5091999769210815, 'test_loss': 1.4291560649871826}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Testing MPL classifier Leaky ReLU---\\n\")\n",
    "trainer.test(model=mlp, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430a301",
   "metadata": {},
   "source": [
    "**Conclusões sobre o Experimento com Leaky ReLU**\n",
    "\n",
    "Os resultados de desempenho foram similares aos obtidos em experimentos anteriores. Contudo, observou-se uma ligeira redução no tempo de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c829de",
   "metadata": {},
   "source": [
    "## Modelo MLP com Dropout\n",
    "\n",
    "Serão utilizados os mesmos parâmetros do [modelo simples](#modelo-mais-simples). Contudo, nesta iteração, será aplicada a técnica de Dropout com uma probabilidade de 50%, a fim de observar e analisar o impacto nos resultados.\n",
    "<center>\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    Input[Entrada<br/>Imagem 3x32x32<br/>Vetor de 3072 características] --> Hidden1(1ª Camada Oculta<br/>64 neurônios<br/>Ativação: ReLU<br/>Dropout: 50%);\n",
    "    Hidden1 --> Hidden2(2ª Camada Oculta<br/>16 neurônios<br/>Ativação: ReLU<br/>Dropout: 50%);\n",
    "    Hidden2 --> Output[Camada de Saída<br/>10 classes neurônios]\n",
    "```\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1f94052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model | Sequential | 197 K  | train\n",
      "---------------------------------------------\n",
      "197 K     Trainable params\n",
      "0         Non-trainable params\n",
      "197 K     Total params\n",
      "0.792     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MLP classifier Dropout---\n",
      "\n",
      "Epoch 38: 100%|██████████| 625/625 [00:12<00:00, 49.66it/s, v_num=58, train_loss_step=1.810, val_loss=1.620, train_loss_epoch=1.760] \n"
     ]
    }
   ],
   "source": [
    "dropout_p = 0.5\n",
    "arch = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3 * 32 * 32, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=dropout_p),\n",
    "    nn.Linear(64, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=dropout_p),\n",
    "    nn.Linear(16, 10),\n",
    ")\n",
    "\n",
    "mlp = LightModel(arch)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5, \n",
    "    mode=\"min\",\n",
    "    min_delta=0.001,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    callbacks=[early_stopping], max_epochs=50, accelerator=device_type, devices=1\n",
    ")\n",
    "print(\"\\n--- Training MLP classifier Dropout---\\n\")\n",
    "\n",
    "trainer.fit(\n",
    "    model=mlp, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4612e412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing MPL classifier Dropout---\n",
      "\n",
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 130.73it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.4189999997615814\n",
      "        test_loss           1.6188361644744873\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.4189999997615814, 'test_loss': 1.6188361644744873}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Testing MPL classifier Dropout---\\n\")\n",
    "trainer.test(model=mlp, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6295c6",
   "metadata": {},
   "source": [
    "**Conclusões sobre a MLP Simples com Dropout**\n",
    "\n",
    "Observou-se um tempo de treinamento consideravelmente estendido, e a acurácia apresentou uma queda significativa. Esse resultado pode indicar que, para a arquitetura em questão, o Dropout não é a técnica de regularização mais adequada, visto que a simplicidade do modelo não demanda a aplicação dessa ferramenta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c79287",
   "metadata": {},
   "source": [
    "## Variação do Número de Neurônios na MLP\n",
    "\n",
    "Nesta etapa, será realizada a variação do número de neurônios nas camadas da MLP com o objetivo de identificar a configuração que otimize a acurácia do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ece1bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model | Sequential | 803 K  | train\n",
      "---------------------------------------------\n",
      "803 K     Trainable params\n",
      "0         Non-trainable params\n",
      "803 K     Total params\n",
      "3.215     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MLP classifier ---\n",
      "\n",
      "Epoch 8: 100%|██████████| 625/625 [00:08<00:00, 74.68it/s, v_num=59, train_loss_step=1.070, val_loss=1.460, train_loss_epoch=0.965] \n"
     ]
    }
   ],
   "source": [
    "arch = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3 * 32 * 32, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10),\n",
    ")\n",
    "\n",
    "mlp = LightModel(arch)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5, \n",
    "    mode=\"min\",\n",
    "    min_delta=0.001,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    callbacks=[early_stopping], max_epochs=50, accelerator=device_type, devices=1\n",
    ")\n",
    "print(\"\\n--- Training MLP classifier ---\\n\")\n",
    "trainer.fit(\n",
    "    model=mlp, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bef178f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing MPL classifier ---\n",
      "\n",
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 112.43it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.5278000235557556\n",
      "        test_loss           1.4579455852508545\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.5278000235557556, 'test_loss': 1.4579455852508545}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Testing MPL classifier ---\\n\")\n",
    "trainer.test(model=mlp, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a160f38",
   "metadata": {},
   "source": [
    "**Conclusões sobre a Variação do Número de Neurônios**\n",
    "\n",
    "Após uma série de experimentos, constatou-se que a configuração com 256 neurônios na primeira camada oculta e 64 neurônios na segunda resultou em um equilíbrio favorável entre acurácia e tempo de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166449b9",
   "metadata": {},
   "source": [
    "## Modelo MLP com Melhores Técnicas\n",
    "\n",
    "Nesta etapa, serão aplicadas as melhores técnicas identificadas em experimentos anteriores, com o objetivo de otimizar o tempo de treinamento e maximizar a precisão. Isso inclui a utilização da função de ativação Leaky ReLU e a configuração do número ótimo de neurônios, conforme determinado previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed4b654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model | Sequential | 803 K  | train\n",
      "---------------------------------------------\n",
      "803 K     Trainable params\n",
      "0         Non-trainable params\n",
      "803 K     Total params\n",
      "3.215     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MLP classifier Best Techs ---\n",
      "\n",
      "Epoch 10: 100%|██████████| 625/625 [00:08<00:00, 73.06it/s, v_num=60, train_loss_step=0.645, val_loss=1.530, train_loss_epoch=0.855]\n"
     ]
    }
   ],
   "source": [
    "arch = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3 * 32 * 32, 256),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(64, 10),\n",
    ")\n",
    "\n",
    "mlp = LightModel(arch)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5, \n",
    "    mode=\"min\",\n",
    "    min_delta=0.001,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    callbacks=[early_stopping], max_epochs=50, accelerator=device_type, devices=1\n",
    ")\n",
    "print(\"\\n--- Training MLP classifier Best Techs ---\\n\")\n",
    "trainer.fit(\n",
    "    model=mlp, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7722ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing MPL classifier Best Techs---\n",
      "\n",
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 118.93it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.5249999761581421\n",
      "        test_loss           1.5264487266540527\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.5249999761581421, 'test_loss': 1.5264487266540527}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Testing MPL classifier Best Techs---\\n\")\n",
    "trainer.test(model=mlp, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a943b39",
   "metadata": {},
   "source": [
    "**Conclusões sobre a MLP com as Melhores Técnicas**\n",
    "\n",
    "O tempo de treinamento transcorreu conforme o esperado, e a acurácia, por sua vez, mostrou-se bastante satisfatória."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43934e69",
   "metadata": {},
   "source": [
    "## Uso da Rede VGG16 Pré-treinada\n",
    "\n",
    "Nesta etapa, será empregada uma rede pré-treinada: a VGG16. A seguir, um diagrama ilustra sua arquitetura."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87131cd7",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TD\n",
    "    subgraph VGG_Model [VGG Model]\n",
    "        direction LR\n",
    "\n",
    "        Input([Input Image:<br/>3x224x224])\n",
    "\n",
    "        subgraph Features_Block [Features]\n",
    "            %%direction LR\n",
    "\n",
    "            fb0[\"Layer: Conv2d<br/>In: 3, Out: 64, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb1[\"Layer: Conv2d<br/>In: 64, Out: 64, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb2[\"Layer: MaxPool2d<br/>Kernel: 2x2, Stride: 2x2\"]\n",
    "\n",
    "            fb3[\"Layer: Conv2d<br/>In: 64, Out: 128, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb4[\"Layer: Conv2d<br/>In: 128, Out: 128, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb5[\"Layer: MaxPool2d<br/>Kernel: 2x2, Stride: 2x2\"]\n",
    "\n",
    "            fb6[\"Layer: Conv2d<br/>In: 128, Out: 256, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb7[\"Layer: Conv2d<br/>In: 256, Out: 256, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb8[\"Layer: Conv2d<br/>In: 256, Out: 256, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb9[\"Layer: MaxPool2d<br/>Kernel: 2x2, Stride: 2x2\"]\n",
    "\n",
    "            fb10[\"Layer: Conv2d<br/>In: 256, Out: 512, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb11[\"Layer: Conv2d<br/>In: 512, Out: 512, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb12[\"Layer: Conv2d<br/>In: 512, Out: 512, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb13[\"Layer: MaxPool2d<br/>Kernel: 2x2, Stride: 2x2\"]\n",
    "\n",
    "            fb14[\"Layer: Conv2d<br/>In: 512, Out: 512, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb15[\"Layer: Conv2d<br/>In: 512, Out: 512, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb16[\"Layer: Conv2d<br/>In: 512, Out: 512, Kernel: 3x3, Stride: 1x1, Padding: 1x1<br/>Activator: ReLU\"]\n",
    "            fb17[\"Layer: MaxPool2d<br/>Kernel: 2x2, Stride: 2x2\"]\n",
    "\n",
    "            fb0 --> fb1 --> fb2 --> fb3 --> fb4 --> fb5 --> fb6 --> fb7 --> fb8 --> fb9 --> fb10\n",
    "            fb10 --> fb11 --> fb12 --> fb13 --> fb14 --> fb15 --> fb16 --> fb17\n",
    "        end\n",
    "\n",
    "        AvgPool[\"(avgpool) Layer: AdaptiveAvgPool2d<br/>Output Size: 7x7\"]\n",
    "\n",
    "        subgraph Classifier_Block [Classifier]\n",
    "            %%direction TD\n",
    "\n",
    "            cb0[\"Layer: Linear<br/>In Feat: 25088, Out Feat: 4096<br/>Activator: ReLU\"]\n",
    "            cb1[\"Layer: Dropout<br/>p: 0.5\"]\n",
    "            cb2[\"Layer: Linear<br/>In Feat: 4096, Out Feat: 4096<br/>Activator: ReLU\"]\n",
    "            cb3[\"Layer: Dropout<br/>p: 0.5\"]\n",
    "            cb4[\"Layer: Linear<br/>In Feat: 4096, Out Feat: 1000\"]\n",
    "\n",
    "            cb0 --> cb1 --> cb2 --> cb3 --> cb4\n",
    "        end\n",
    "\n",
    "        Output([Output:<br/>1000 classes])\n",
    "\n",
    "        Input --> Features_Block\n",
    "        Features_Block --> AvgPool\n",
    "        AvgPool --> Classifier_Block\n",
    "        Classifier_Block --> Output\n",
    "    end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a77d7",
   "metadata": {},
   "source": [
    "Será realizada a modificação da camada classificadora da rede VGG16. A arquitetura VGG16 pré-treinada exige como entrada imagens com dimensões de 244x244 pixels e 3 canais de cor. Consequentemente, será necessário redimensionar o dataset para se adequar a este requisito.\n",
    "\n",
    "Para otimizar o processo de treinamento, **será empregada a função de ativação Leaky ReLU**, uma vez que experimentos anteriores indicaram um aumento na velocidade de treinamento. Em contrapartida, **o Dropout não será aplicado**, pois testes prévios com modelos de menor complexidade demonstraram que essa técnica não resultou em benefícios significativos.\n",
    "\n",
    "Abaixo, um diagrama ilustra a estrutura da nova camada classificadora que será definida. Além disso, as classes de saída também precisarão ser ajustadas para corresponder ao nosso problema de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f666f84",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR   \n",
    "    subgraph Classifier_Block [Classifier Block]\n",
    "        direction LR\n",
    "        cb0[\"Layer: Linear<br/>In Feat: 25088, Out Feat: 256<br/>Activator: Leaky ReLU\"]\n",
    "        cb2[\"Layer: Linear<br/>In Feat: 256, Out Feat: 64<br/>Activator: Leaky ReLU\"]\n",
    "        cb4[\"Layer: Linear<br/>In Feat: 64, Out Feat: 10\"]\n",
    "\n",
    "        cb0  --> cb2 --> cb4\n",
    "    end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e262d34",
   "metadata": {},
   "source": [
    "### Ajustar dataset Resize 244 x 244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17e34ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFAR10Dataset(root=root, resize=(244, 244))\n",
    "train_dataloader = dataset.get_dataloader(dataset_type=\"train\", num_workers=num_workers)\n",
    "val_dataloader = dataset.get_dataloader(dataset_type=\"val\", num_workers=num_workers)\n",
    "test_dataloader = dataset.get_dataloader(dataset_type=\"val\", num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a7df4",
   "metadata": {},
   "source": [
    "### Requisição de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf7b6f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = vgg16(weights=VGG16_Weights.DEFAULT, progress=True)\n",
    "\n",
    "for param in model_vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "in_features = cast(int, model_vgg.classifier[0].in_features) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b010f4",
   "metadata": {},
   "source": [
    "### Classifier Costumizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5826bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features, 128),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "model_vgg.classifier = custom_classifier\n",
    "\n",
    "light_vgg_model = LightModel(model=model_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "055e497c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params | Mode \n",
      "---------------------------------------\n",
      "0 | model | VGG  | 17.9 M | train\n",
      "---------------------------------------\n",
      "3.2 M     Trainable params\n",
      "14.7 M    Non-trainable params\n",
      "17.9 M    Total params\n",
      "71.740    Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training VGG16 with custom classifier ---\n",
      "\n",
      "Epoch 0:   0%|          | 2/625 [00:48<4:11:40,  0.04it/s, v_num=61, train_loss_step=2.260]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 43, in do_one_step\n    data = pin_memory(data, device)\n  File \"c:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 100, in pin_memory\n    clone[i] = pin_memory(item, device)\n               ~~~~~~~~~~^^^^^^^^^^^^^^\n  File \"c:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 66, in pin_memory\n    return data.pin_memory(device)\n           ~~~~~~~~~~~~~~~^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m trainer = Trainer(\n\u001b[32m      8\u001b[39m     callbacks=[early_stopping], max_epochs=\u001b[32m50\u001b[39m, accelerator=device_type, devices=\u001b[32m1\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Training VGG16 with custom classifier ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlight_vgg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataloader\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     51\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    592\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    602\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1017\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1054\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_sanity_check()\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.state\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end()\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_epoch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:282\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    281\u001b[39m     dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     batch, _, __ = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m     \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[32m    284\u001b[39m     \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n\u001b[32m    285\u001b[39m     batch_idx = \u001b[38;5;28mself\u001b[39m.batch_idx + \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:134\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    131\u001b[39m         \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batches\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     batch = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:61\u001b[39m, in \u001b[36m_DataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mself\u001b[39m._start_profiler()\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:341\u001b[39m, in \u001b[36mCombinedLoader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ITERATOR_RETURN:\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     out = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator, _Sequential):\n\u001b[32m    343\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:78\u001b[39m, in \u001b[36m_MaxSizeCycle.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         out[i] = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28mself\u001b[39m._consumed[i] = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1515\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1513\u001b[39m worker_id = \u001b[38;5;28mself\u001b[39m._task_info.pop(idx)[\u001b[32m0\u001b[39m]\n\u001b[32m   1514\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1515\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1550\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data, worker_idx)\u001b[39m\n\u001b[32m   1548\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\torch\\_utils.py:750\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    747\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[32m    748\u001b[39m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mRuntimeError\u001b[39m: Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 43, in do_one_step\n    data = pin_memory(data, device)\n  File \"c:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 100, in pin_memory\n    clone[i] = pin_memory(item, device)\n               ~~~~~~~~~~^^^^^^^^^^^^^^\n  File \"c:\\Dev\\Coding\\personal\\Curso\\ML\\ENE0082\\Trabalhos\\Trabaho 3\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 66, in pin_memory\n    return data.pin_memory(device)\n           ~~~~~~~~~~~~~~~^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5, \n",
    "    mode=\"min\",\n",
    "    min_delta=0.001,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    callbacks=[early_stopping], max_epochs=50, accelerator=device_type, devices=1\n",
    ")\n",
    "print(\"\\n--- Training VGG16 with custom classifier ---\\n\")\n",
    "trainer.fit(\n",
    "    model=light_vgg_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cbfc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Testing VGG16 with custom classifier ---\\n\")\n",
    "trainer.test(model=light_vgg_model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d913b77",
   "metadata": {},
   "source": [
    "**Conclusões sobre o Modelo VGG16**\n",
    "\n",
    "O tempo de treinamento para o modelo VGG16 foi consideravelmente extenso (95 Minutos). A acurácia alcançada foi de 81%, um resultado que pode ser considerado satisfatório.\n",
    "\n",
    "Embora potenciais ajustes nos parâmetros das camadas de entrada e saída da camada classificadora pudessem, em tese, levar a uma acurácia ainda maior, a manutenção de um processo de treinamento tão prolongado é inviável.\n",
    "\n",
    "Dessa forma, a acurácia de 81% é aceita como um resultado adequado para os propósitos deste estudo, considerando o *trade-off* entre desempenho e custo computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373d299",
   "metadata": {},
   "source": [
    "## Modelo Inception V3 da Google\n",
    "\n",
    "Nesta etapa, serão aplicadas as mesmas técnicas ao modelo Inception V3.\n",
    "\n",
    "O modelo Inception V3 representa uma escolha adequada para esta aplicação, dada a sua natureza predominantemente convolucional e a simplicidade de sua camada de saída linear. Essas características sugerem uma boa capacidade de generalização para o dataset CIFAR-10, mesmo com uma entrada de complexidade relativamente menor em comparação aos dados de pré-treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239808a6",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TD\n",
    "    subgraph Inception3_Model [InceptionV3 Model]\n",
    "        %%direction TD\n",
    "\n",
    "        Input([Input Image:<br/>3 channels])\n",
    "\n",
    "        subgraph Stem_Block [Stem Layers]\n",
    "            %%direction TD\n",
    "            bc1a[\"Conv2d_1a_3x3:<br/>Conv(3, 32, k=3, s=2) + BN + ReLU\"]\n",
    "            bc2a[\"Conv2d_2a_3x3:<br/>Conv(32, 32, k=3, s=1) + BN + ReLU\"]\n",
    "            bc2b[\"Conv2d_2b_3x3:<br/>Conv(32, 64, k=3, s=1, p=1) + BN + ReLU\"]\n",
    "            mp1[\"maxpool1:<br/>MaxPool2d(k=3, s=2, p=0)\"]\n",
    "            bc3b[\"Conv2d_3b_1x1:<br/>Conv(64, 80, k=1, s=1) + BN + ReLU\"]\n",
    "            bc4a[\"Conv2d_4a_3x3:<br/>Conv(80, 192, k=3, s=1) + BN + ReLU\"]\n",
    "            mp2[\"maxpool2:<br/>MaxPool2d(k=3, s=2, p=0)\"]\n",
    "\n",
    "            bc1a --> bc2a --> bc2b --> mp1 --> bc3b --> bc4a --> mp2\n",
    "        end\n",
    "\n",
    "        subgraph Mixed_5b_Block [\"Mixed_5b (InceptionA) Out: 256\"]\n",
    "            direction LR\n",
    "            in_5b(\"Input(192)\")\n",
    "\n",
    "            subgraph Branch1x1_5b [Branch 1x1]\n",
    "                bc1x1_5b[\"branch1x1:<br/>Conv(192, 64, k=1) + BN + ReLU\"]\n",
    "            end\n",
    "\n",
    "            subgraph Branch5x5_5b [Branch 5x5]\n",
    "                b5x5_1_5b[\"branch5x5_1:<br/>Conv(192, 48, k=1) + BN + ReLU\"]\n",
    "                b5x5_2_5b[\"branch5x5_2:<br/>Conv(48, 64, k=5, p=2) + BN + ReLU\"]\n",
    "                b5x5_1_5b --> b5x5_2_5b\n",
    "            end\n",
    "\n",
    "            subgraph Branch3x3dbl_5b [Branch 3x3 Dbl]\n",
    "                b3x3dbl_1_5b[\"branch3x3dbl_1:<br/>Conv(192, 64, k=1) + BN + ReLU\"]\n",
    "                b3x3dbl_2_5b[\"branch3x3dbl_2:<br/>Conv(64, 96, k=3, p=1) + BN + ReLU\"]\n",
    "                b3x3dbl_3_5b[\"branch3x3dbl_3:<br/>Conv(96, 96, k=3, p=1) + BN + ReLU\"]\n",
    "                b3x3dbl_1_5b --> b3x3dbl_2_5b --> b3x3dbl_3_5b\n",
    "            end\n",
    "\n",
    "            subgraph BranchPool_5b [Branch Pool]\n",
    "                mpool_5b(\"AvgPool2d(k=3, s=1, p=1)\")\n",
    "                bp_5b[\"branch_pool:<br/>Conv(192, 32, k=1) + BN + ReLU\"]\n",
    "                mpool_5b --> bp_5b\n",
    "            end\n",
    "\n",
    "            in_5b --\"Input\"--> Branch1x1_5b\n",
    "            in_5b --\"Input\"--> Branch5x5_5b\n",
    "            in_5b --\"Input\"--> Branch3x3dbl_5b\n",
    "            in_5b --\"Input\"--> BranchPool_5b\n",
    "\n",
    "            bc1x1_5b & b5x5_2_5b & b3x3dbl_3_5b & bp_5b --> Concat_5b((Concatenate:<br/>256 channels))\n",
    "        end\n",
    "\n",
    "        subgraph Mixed_5c_Block [\"Mixed_5c (InceptionA) Out: 288\"]\n",
    "            direction LR\n",
    "            in_5c(\"Input(256)\")\n",
    "            subgraph Branch1x1_5c\n",
    "                bc1x1_5c[\"branch1x1:<br/>Conv(256, 64, k=1) + BN + ReLU\"]\n",
    "            end\n",
    "            subgraph Branch5x5_5c\n",
    "                b5x5_1_5c[\"branch5x5_1:<br/>Conv(256, 48, k=1) + BN + ReLU\"]\n",
    "                b5x5_2_5c[\"branch5x5_2:<br/>Conv(48, 64, k=5, p=2) + BN + ReLU\"]\n",
    "                b5x5_1_5c --> b5x5_2_5c\n",
    "            end\n",
    "            subgraph Branch3x3dbl_5c\n",
    "                b3x3dbl_1_5c[\"branch3x3dbl_1:<br/>Conv(256, 64, k=1) + BN + ReLU\"]\n",
    "                b3x3dbl_2_5c[\"branch3x3dbl_2:<br/>Conv(64, 96, k=3, p=1) + BN + ReLU\"]\n",
    "                b3x3dbl_3_5c[\"branch3x3dbl_3:<br/>Conv(96, 96, k=3, p=1) + BN + ReLU\"]\n",
    "                b3x3dbl_1_5c --> b3x3dbl_2_5c --> b3x3dbl_3_5c\n",
    "            end\n",
    "            subgraph BranchPool_5c\n",
    "                mpool_5c(\"AvgPool2d(k=3, s=1, p=1)\")\n",
    "                bp_5c[\"branch_pool:<br/>Conv(256, 64, k=1) + BN + ReLU\"]\n",
    "                mpool_5c --> bp_5c\n",
    "            end\n",
    "            in_5c --\"Input\"--> Branch1x1_5c\n",
    "            in_5c --\"Input\"--> Branch5x5_5c\n",
    "            in_5c --\"Input\"--> Branch3x3dbl_5c\n",
    "            in_5c --\"Input\"--> BranchPool_5c\n",
    "            bc1x1_5c & b5x5_2_5c & b3x3dbl_3_5c & bp_5c --> Concat_5c((Concatenate:<br/>288 channels))\n",
    "        end\n",
    "\n",
    "        subgraph Mixed_5d_Block [\"Mixed_5d (InceptionA) Out: 288\"]\n",
    "            direction LR\n",
    "            in_5d(\"Input(288)\")\n",
    "            subgraph Branch1x1_5d\n",
    "                bc1x1_5d[\"branch1x1:<br/>Conv(288, 64, k=1) + BN + ReLU\"]\n",
    "            end\n",
    "            subgraph Branch5x5_5d\n",
    "                b5x5_1_5d[\"branch5x5_1:<br/>Conv(288, 48, k=1) + BN + ReLU\"]\n",
    "                b5x5_2_5d[\"branch5x5_2:<br/>Conv(48, 64, k=5, p=2) + BN + ReLU\"]\n",
    "                b5x5_1_5d --> b5x5_2_5d\n",
    "            end\n",
    "            subgraph Branch3x3dbl_5d\n",
    "                b3x3dbl_1_5d[\"branch3x3dbl_1:<br/>Conv(288, 64, k=1) + BN + ReLU\"]\n",
    "                b3x3dbl_2_5d[\"branch3x3dbl_2:<br/>Conv(64, 96, k=3, p=1) + BN + ReLU\"]\n",
    "                b3x3dbl_3_5d[\"branch3x3dbl_3:<br/>Conv(96, 96, k=3, p=1) + BN + ReLU\"]\n",
    "                b3x3dbl_1_5d --> b3x3dbl_2_5d --> b3x3dbl_3_5d\n",
    "            end\n",
    "            subgraph BranchPool_5d\n",
    "                mpool_5d(\"AvgPool2d(k=3, s=1, p=1)\")\n",
    "                bp_5d[\"branch_pool:<br/>Conv(288, 64, k=1) + BN + ReLU\"]\n",
    "                mpool_5d --> bp_5d\n",
    "            end\n",
    "            in_5d --\"Input\"--> Branch1x1_5d\n",
    "            in_5d --\"Input\"--> Branch5x5_5d\n",
    "            in_5d --\"Input\"--> Branch3x3dbl_5d\n",
    "            in_5d --\"Input\"--> BranchPool_5d\n",
    "            bc1x1_5d & b5x5_2_5d & b3x3dbl_3_5d & bp_5d --> Concat_5d((Concatenate:<br/>288 channels))\n",
    "        end\n",
    "\n",
    "        subgraph Mixed_6a_Block [\"Mixed_6a (InceptionB) Out: 768\"]\n",
    "            direction LR\n",
    "            in_6a(\"Input(288)\")\n",
    "\n",
    "            subgraph Branch3x3_6a [Branch 3x3]\n",
    "                b3x3_6a[\"branch3x3:<br/>Conv(288, 384, k=3, s=2) + BN + ReLU\"]\n",
    "            end\n",
    "\n",
    "            subgraph Branch3x3dbl_6a [Branch 3x3 Dbl]\n",
    "                b3x3dbl_1_6a[\"branch3x3dbl_1:<br/>Conv(288, 64, k=1) + BN + ReLU\"]\n",
    "                b3x3dbl_2_6a[\"branch3x3dbl_2:<br/>Conv(64, 96, k=3, p=1) + BN + ReLU\"]\n",
    "                b3x3dbl_3_6a[\"branch3x3dbl_3:<br/>Conv(96, 96, k=3, s=2) + BN + ReLU\"]\n",
    "                b3x3dbl_1_6a --> b3x3dbl_2_6a --> b3x3dbl_3_6a\n",
    "            end\n",
    "\n",
    "            subgraph MaxPool_6a [Max Pool]\n",
    "                mpool_6a(\"MaxPool2d(k=3, s=2, p=0)\")\n",
    "            end\n",
    "\n",
    "            in_6a --\"Input\"--> Branch3x3_6a\n",
    "            in_6a --\"Input\"--> Branch3x3dbl_6a\n",
    "            in_6a --\"Input\"--> MaxPool_6a\n",
    "\n",
    "            b3x3_6a & b3x3dbl_3_6a & mpool_6a --> Concat_6a((Concatenate:<br/>768 channels))\n",
    "        end\n",
    "\n",
    "        subgraph Mixed_6b_Block [\"Mixed_6b (InceptionC) Out: 768\"]\n",
    "            direction LR\n",
    "            in_6b(\"Input(768)\")\n",
    "\n",
    "            subgraph Branch1x1_6b [Branch 1x1]\n",
    "                bc1x1_6b[\"branch1x1:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "            end\n",
    "\n",
    "            subgraph Branch7x7_6b [Branch 7x7]\n",
    "                b7x7_1_6b[\"branch7x7_1:<br/>Conv(768, 128, k=1) + BN + ReLU\"]\n",
    "                b7x7_2_6b[\"branch7x7_2:<br/>Conv(128, 128, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7_3_6b[\"branch7x7_3:<br/>Conv(128, 192, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7_1_6b --> b7x7_2_6b --> b7x7_3_6b\n",
    "            end\n",
    "\n",
    "            subgraph Branch7x7dbl_6b [Branch 7x7 Dbl]\n",
    "                b7x7dbl_1_6b[\"branch7x7dbl_1:<br/>Conv(768, 128, k=1) + BN + ReLU\"]\n",
    "                b7x7dbl_2_6b[\"branch7x7dbl_2:<br/>Conv(128, 128, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7dbl_3_6b[\"branch7x7dbl_3:<br/>Conv(128, 128, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7dbl_4_6b[\"branch7x7dbl_4:<br/>Conv(128, 128, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7dbl_5_6b[\"branch7x7dbl_5:<br/>Conv(128, 192, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7dbl_1_6b --> b7x7dbl_2_6b --> b7x7dbl_3_6b --> b7x7dbl_4_6b --> b7x7dbl_5_6b\n",
    "            end\n",
    "\n",
    "            subgraph BranchPool_6b [Branch Pool]\n",
    "                mpool_6b(\"AvgPool2d(k=3, s=1, p=1)\")\n",
    "                bp_6b[\"branch_pool:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "                mpool_6b --> bp_6b\n",
    "            end\n",
    "\n",
    "            in_6b --\"Input\"--> Branch1x1_6b\n",
    "            in_6b --\"Input\"--> Branch7x7_6b\n",
    "            in_6b --\"Input\"--> Branch7x7dbl_6b\n",
    "            in_6b --\"Input\"--> BranchPool_6b\n",
    "\n",
    "            bc1x1_6b & b7x7_3_6b & b7x7dbl_5_6b & bp_6b --> Concat_6b((Concatenate:<br/>768 channels))\n",
    "        end\n",
    "\n",
    "        subgraph Mixed_6c_Block [\"Mixed_6c (InceptionC) Out: 768\"]\n",
    "            direction LR\n",
    "            in_6c(\"Input(768)\")\n",
    "            subgraph Branch1x1_6c\n",
    "                bc1x1_6c[\"branch1x1:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "            end\n",
    "            subgraph Branch7x7_6c\n",
    "                b7x7_1_6c[\"branch7x7_1:<br/>Conv(768, 160, k=1) + BN + ReLU\"]\n",
    "                b7x7_2_6c[\"branch7x7_2:<br/>Conv(160, 160, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7_3_6c[\"branch7x7_3:<br/>Conv(160, 192, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7_1_6c --> b7x7_2_6c --> b7x7_3_6c\n",
    "            end\n",
    "            subgraph Branch7x7dbl_6c\n",
    "                b7x7dbl_1_6c[\"branch7x7dbl_1:<br/>Conv(768, 160, k=1) + BN + ReLU\"]\n",
    "                b7x7dbl_2_6c[\"branch7x7dbl_2:<br/>Conv(160, 160, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7dbl_3_6c[\"branch7x7dbl_3:<br/>Conv(160, 160, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7dbl_4_6c[\"branch7x7dbl_4:<br/>Conv(160, 160, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7dbl_5_6c[\"branch7x7dbl_5:<br/>Conv(160, 192, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7dbl_1_6c --> b7x7dbl_2_6c --> b7x7dbl_3_6c --> b7x7dbl_4_6c --> b7x7dbl_5_6c\n",
    "            end\n",
    "            subgraph BranchPool_6c\n",
    "                mpool_6c(\"AvgPool2d(k=3, s=1, p=1)\")\n",
    "                bp_6c[\"branch_pool:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "                mpool_6c --> bp_6c\n",
    "            end\n",
    "            in_6c --\"Input\"--> Branch1x1_6c\n",
    "            in_6c --\"Input\"--> Branch7x7_6c\n",
    "            in_6c --\"Input\"--> Branch7x7dbl_6c\n",
    "            in_6c --\"Input\"--> BranchPool_6c\n",
    "            bc1x1_6c & b7x7_3_6c & b7x7dbl_5_6c & bp_6c --> Concat_6c((Concatenate:<br/>768 channels))\n",
    "        end\n",
    "\n",
    "        subgraph Mixed_6d_Block [\"Mixed_6d (InceptionC) Out: 768\"]\n",
    "            direction LR\n",
    "            in_6d(\"Input(768)\")\n",
    "            subgraph Branch1x1_6d\n",
    "                bc1x1_6d[\"branch1x1:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "            end\n",
    "            subgraph Branch7x7_6d\n",
    "                b7x7_1_6d[\"branch7x7_1:<br/>Conv(768, 160, k=1) + BN + ReLU\"]\n",
    "                b7x7_2_6d[\"branch7x7_2:<br/>Conv(160, 160, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7_3_6d[\"branch7x7_3:<br/>Conv(160, 192, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7_1_6d --> b7x7_2_6d --> b7x7_3_6d\n",
    "            end\n",
    "            subgraph Branch7x7dbl_6d\n",
    "                b7x7dbl_1_6d[\"branch7x7dbl_1:<br/>Conv(768, 160, k=1) + BN + ReLU\"]\n",
    "                b7x7dbl_2_6d[\"branch7x7dbl_2:<br/>Conv(160, 160, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7dbl_3_6d[\"branch7x7dbl_3:<br/>Conv(160, 160, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7dbl_4_6d[\"branch7x7dbl_4:<br/>Conv(160, 160, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7dbl_5_6d[\"branch7x7dbl_5:<br/>Conv(160, 192, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7dbl_1_6d --> b7x7dbl_2_6d --> b7x7dbl_3_6d --> b7x7dbl_4_6d --> b7x7dbl_5_6d\n",
    "            end\n",
    "            subgraph BranchPool_6d\n",
    "                mpool_6d(\"AvgPool2d(k=3, s=1, p=1)\")\n",
    "                bp_6d[\"branch_pool:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "                mpool_6d --> bp_6d\n",
    "            end\n",
    "            in_6d --\"Input\"--> Branch1x1_6d\n",
    "            in_6d --\"Input\"--> Branch7x7_6d\n",
    "            in_6d --\"Input\"--> Branch7x7dbl_6d\n",
    "            in_6d --\"Input\"--> BranchPool_6d\n",
    "            bc1x1_6d & b7x7_3_6d & b7x7dbl_5_6d & bp_6d --> Concat_6d((Concatenate:<br/>768 channels))\n",
    "        end\n",
    "\n",
    "        subgraph Mixed_6e_Block [\"Mixed_6e (InceptionC) Out: 768\"]\n",
    "            direction LR\n",
    "            in_6e(\"Input(768)\")\n",
    "            subgraph Branch1x1_6e\n",
    "                bc1x1_6e[\"branch1x1:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "            end\n",
    "            subgraph Branch7x7_6e\n",
    "                b7x7_1_6e[\"branch7x7_1:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "                b7x7_2_6e[\"branch7x7_2:<br/>Conv(192, 192, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7_3_6e[\"branch7x7_3:<br/>Conv(192, 192, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7_1_6e --> b7x7_2_6e --> b7x7_3_6e\n",
    "            end\n",
    "            subgraph Branch7x7dbl_6e\n",
    "                b7x7dbl_1_6e[\"branch7x7dbl_1:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "                b7x7dbl_2_6e[\"branch7x7dbl_2:<br/>Conv(192, 192, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7dbl_3_6e[\"branch7x7dbl_3:<br/>Conv(192, 192, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7dbl_4_6e[\"branch7x7dbl_4:<br/>Conv(192, 192, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7dbl_5_6e[\"branch7x7dbl_5:<br/>Conv(192, 192, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7dbl_1_6e --> b7x7dbl_2_6e --> b7x7dbl_3_6e --> b7x7dbl_4_6e --> b7x7dbl_5_6e\n",
    "            end\n",
    "            subgraph BranchPool_6e\n",
    "                mpool_6e(\"AvgPool2d(k=3, s=1, p=1)\")\n",
    "                bp_6e[\"branch_pool:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "                mpool_6e --> bp_6e\n",
    "            end\n",
    "            in_6e --\"Input\"--> Branch1x1_6e\n",
    "            in_6e --\"Input\"--> Branch7x7_6e\n",
    "            in_6e --\"Input\"--> Branch7x7dbl_6e\n",
    "            in_6e --\"Input\"--> BranchPool_6e\n",
    "            bc1x1_6e & b7x7_3_6e & b7x7dbl_5_6e & bp_6e --> Concat_6e((Concatenate:<br/>768 channels))\n",
    "        end\n",
    "\n",
    "        subgraph AuxLogits_Block [AuxLogits Classifier]\n",
    "            %%direction TD\n",
    "            in_aux(\"Input(768 from Mixed_6e)\")\n",
    "            aux_avgpool_5x5[\"Aux AvgPool:<br/>AdaptiveAvgPool2d(Out: (5,5))\"]\n",
    "            aux_conv0[\"conv0:<br/>Conv(768, 128, k=1) + BN + ReLU\"]\n",
    "            aux_conv1[\"conv1:<br/>Conv(128, 768, k=5) + BN + ReLU\"]\n",
    "            aux_avgpool_1x1[\"Aux AvgPool:<br/>AdaptiveAvgPool2d(Out: (1,1))\"]\n",
    "            aux_flatten[\"Flatten\"]\n",
    "            aux_fc[\"fc:<br/>Linear(768, 1000)\"]\n",
    "            in_aux --> aux_avgpool_5x5 --> aux_conv0 --> aux_conv1 --> aux_avgpool_1x1 --> aux_flatten --> aux_fc\n",
    "        end\n",
    "\n",
    "        subgraph Mixed_7a_Block [\"Mixed_7a (InceptionD) Out: 1280\"]\n",
    "            direction LR\n",
    "            in_7a(\"Input(768)\")\n",
    "\n",
    "            subgraph Branch3x3_7a [Branch 3x3]\n",
    "                b3x3_1_7a[\"branch3x3_1:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "                b3x3_2_7a[\"branch3x3_2:<br/>Conv(192, 320, k=3, s=2) + BN + ReLU\"]\n",
    "                b3x3_1_7a --> b3x3_2_7a\n",
    "            end\n",
    "\n",
    "            subgraph Branch7x7x3_7a [Branch 7x7x3]\n",
    "                b7x7x3_1_7a[\"branch7x7x3_1:<br/>Conv(768, 192, k=1) + BN + ReLU\"]\n",
    "                b7x7x3_2_7a[\"branch7x7x3_2:<br/>Conv(192, 192, k=1x7, p=0,3) + BN + ReLU\"]\n",
    "                b7x7x3_3_7a[\"branch7x7x3_3:<br/>Conv(192, 192, k=7x1, p=3,0) + BN + ReLU\"]\n",
    "                b7x7x3_4_7a[\"branch7x7x3_4:<br/>Conv(192, 192, k=3, s=2) + BN + ReLU\"]\n",
    "                b7x7x3_1_7a --> b7x7x3_2_7a --> b7x7x3_3_7a --> b7x7x3_4_7a\n",
    "            end\n",
    "\n",
    "            subgraph MaxPool_7a [Max Pool]\n",
    "                mpool_7a(\"MaxPool2d(k=3, s=2, p=0)\")\n",
    "            end\n",
    "\n",
    "            in_7a --\"Input\"--> Branch3x3_7a\n",
    "            in_7a --\"Input\"--> Branch7x7x3_7a\n",
    "            in_7a --\"Input\"--> MaxPool_7a\n",
    "\n",
    "            b3x3_2_7a & b7x7x3_4_7a & mpool_7a --> Concat_7a((Concatenate:<br/>1280 channels))\n",
    "        end\n",
    "\n",
    "        subgraph Mixed_7b_Block [\"Mixed_7b (InceptionE) Out: 2048\"]\n",
    "            direction LR\n",
    "            in_7b(\"Input(1280)\")\n",
    "\n",
    "            subgraph Branch1x1_7b [Branch 1x1]\n",
    "                bc1x1_7b[\"branch1x1:<br/>Conv(1280, 320, k=1) + BN + ReLU\"]\n",
    "            end\n",
    "\n",
    "            subgraph Branch3x3_7b [Branch 3x3]\n",
    "                b3x3_1_7b[\"branch3x3_1:<br/>Conv(1280, 384, k=1) + BN + ReLU\"]\n",
    "                split_3x3_7b{{\"Split\"}}\n",
    "                b3x3_2a_7b[\"branch3x3_2a:<br/>Conv(384, 384, k=1x3, p=0,1) + BN + ReLU\"]\n",
    "                b3x3_2b_7b[\"branch3x3_2b:<br/>Conv(384, 384, k=3x1, p=1,0) + BN + ReLU\"]\n",
    "                b3x3_1_7b --> split_3x3_7b\n",
    "                split_3x3_7b --\"H-Split\"--> b3x3_2a_7b\n",
    "                split_3x3_7b --\"V-Split\"--> b3x3_2b_7b\n",
    "                b3x3_2a_7b & b3x3_2b_7b --> Concat_3x3_7b((Concat: 768))\n",
    "            end\n",
    "\n",
    "            subgraph Branch3x3dbl_7b [Branch 3x3 Dbl]\n",
    "                b3x3dbl_1_7b[\"branch3x3dbl_1:<br/>Conv(1280, 448, k=1) + BN + ReLU\"]\n",
    "                b3x3dbl_2_7b[\"branch3x3dbl_2:<br/>Conv(448, 384, k=3, p=1) + BN + ReLU\"]\n",
    "                split_3x3dbl_7b{{\"Split\"}}\n",
    "                b3x3dbl_3a_7b[\"branch3x3dbl_3a:<br/>Conv(384, 384, k=1x3, p=0,1) + BN + ReLU\"]\n",
    "                b3x3dbl_3b_7b[\"branch3x3dbl_3b:<br/>Conv(384, 384, k=3x1, p=1,0) + BN + ReLU\"]\n",
    "                b3x3dbl_1_7b --> b3x3dbl_2_7b --> split_3x3dbl_7b\n",
    "                split_3x3dbl_7b --\"H-Split\"--> b3x3dbl_3a_7b\n",
    "                split_3x3dbl_7b --\"V-Split\"--> b3x3dbl_3b_7b\n",
    "                b3x3dbl_3a_7b & b3x3dbl_3b_7b --> Concat_3x3dbl_7b((Concat: 768))\n",
    "            end\n",
    "\n",
    "            subgraph BranchPool_7b [Branch Pool]\n",
    "                mpool_7b(\"AvgPool2d(k=3, s=1, p=1)\")\n",
    "                bp_7b[\"branch_pool:<br/>Conv(1280, 192, k=1) + BN + ReLU\"]\n",
    "                mpool_7b --> bp_7b\n",
    "            end\n",
    "\n",
    "            in_7b --\"Input\"--> Branch1x1_7b\n",
    "            in_7b --\"Input\"--> Branch3x3_7b\n",
    "            in_7b --\"Input\"--> Branch3x3dbl_7b\n",
    "            in_7b --\"Input\"--> BranchPool_7b\n",
    "\n",
    "            bc1x1_7b & Concat_3x3_7b & Concat_3x3dbl_7b & bp_7b --> Concat_7b((Concatenate:<br/>2048 channels))\n",
    "        end\n",
    "\n",
    "        subgraph Mixed_7c_Block [\"Mixed_7c (InceptionE) Out: 2048\"]\n",
    "            direction LR\n",
    "            in_7c(\"Input(2048)\")\n",
    "            subgraph Branch1x1_7c\n",
    "                bc1x1_7c[\"branch1x1:<br/>Conv(2048, 320, k=1) + BN + ReLU\"]\n",
    "            end\n",
    "            subgraph Branch3x3_7c\n",
    "                b3x3_1_7c[\"branch3x3_1:<br/>Conv(2048, 384, k=1) + BN + ReLU\"]\n",
    "                split_3x3_7c{{\"Split\"}}\n",
    "                b3x3_2a_7c[\"branch3x3_2a:<br/>Conv(384, 384, k=1x3, p=0,1) + BN + ReLU\"]\n",
    "                b3x3_2b_7c[\"branch3x3_2b:<br/>Conv(384, 384, k=3x1, p=1,0) + BN + ReLU\"]\n",
    "                b3x3_1_7c --> split_3x3_7c\n",
    "                split_3x3_7c --\"H-Split\"--> b3x3_2a_7c\n",
    "                split_3x3_7c --\"V-Split\"--> b3x3_2b_7c\n",
    "                b3x3_2a_7c & b3x3_2b_7c --> Concat_3x3_7c((Concat: 768))\n",
    "            end\n",
    "            subgraph Branch3x3dbl_7c\n",
    "                b3x3dbl_1_7c[\"branch3x3dbl_1:<br/>Conv(2048, 448, k=1) + BN + ReLU\"]\n",
    "                b3x3dbl_2_7c[\"branch3x3dbl_2:<br/>Conv(448, 384, k=3, p=1) + BN + ReLU\"]\n",
    "                split_3x3dbl_7c{{\"Split\"}}\n",
    "                b3x3dbl_3a_7c[\"branch3x3dbl_3a:<br/>Conv(384, 384, k=1x3, p=0,1) + BN + ReLU\"]\n",
    "                b3x3dbl_3b_7c[\"branch3x3dbl_3b:<br/>Conv(384, 384, k=3x1, p=1,0) + BN + ReLU\"]\n",
    "                b3x3dbl_1_7c --> b3x3dbl_2_7c --> split_3x3dbl_7c\n",
    "                split_3x3dbl_7c --\"H-Split\"--> b3x3dbl_3a_7c\n",
    "                split_3x3dbl_7c --\"V-Split\"--> b3x3dbl_3b_7c\n",
    "                b3x3dbl_3a_7c & b3x3dbl_3b_7c --> Concat_3x3dbl_7c((Concat: 768))\n",
    "            end\n",
    "            subgraph BranchPool_7c\n",
    "                mpool_7c(\"AvgPool2d(k=3, s=1, p=1)\")\n",
    "                bp_7c[\"branch_pool:<br/>Conv(2048, 192, k=1) + BN + ReLU\"]\n",
    "                mpool_7c --> bp_7c\n",
    "            end\n",
    "            in_7c --\"Input\"--> Branch1x1_7c\n",
    "            in_7c --\"Input\"--> Branch3x3_7c\n",
    "            in_7c --\"Input\"--> Branch3x3dbl_7c\n",
    "            in_7c --\"Input\"--> BranchPool_7c\n",
    "            bc1x1_7c & Concat_3x3_7c & Concat_3x3dbl_7c & bp_7c --> Concat_7c((Concatenate:<br/>2048 channels))\n",
    "        end\n",
    "\n",
    "        subgraph Final_Layers [Classifier Head]\n",
    "            avgpool[\"avgpool:<br/>AdaptiveAvgPool2d(Out: (1,1))\"]\n",
    "            dropout[\"dropout:<br/>Dropout(p=0.5)\"]\n",
    "            fc[\"fc:<br/>Linear(2048, 1000)\"]\n",
    "            avgpool --> dropout --> fc\n",
    "        end\n",
    "\n",
    "        Input --> Stem_Block\n",
    "        Stem_Block --> Mixed_5b_Block\n",
    "        Mixed_5b_Block --> Mixed_5c_Block\n",
    "        Mixed_5c_Block --> Mixed_5d_Block\n",
    "        Mixed_5d_Block --> Mixed_6a_Block\n",
    "        Mixed_6a_Block --> Mixed_6b_Block\n",
    "        Mixed_6b_Block --> Mixed_6c_Block\n",
    "        Mixed_6c_Block --> Mixed_6d_Block\n",
    "        Mixed_6d_Block --> Mixed_6e_Block\n",
    "\n",
    "        Mixed_6e_Block --\"Main path\"--> Mixed_7a_Block\n",
    "        Mixed_6e_Block --\"Auxiliary path\"--> AuxLogits_Block\n",
    "\n",
    "        Mixed_7a_Block --> Mixed_7b_Block\n",
    "        Mixed_7b_Block --> Mixed_7c_Block\n",
    "        Mixed_7c_Block --> Final_Layers\n",
    "        Final_Layers --> Output\n",
    "    end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b96029",
   "metadata": {},
   "source": [
    "## Redimensionamento do Dataset para 299x299 Pixels\n",
    "\n",
    "Nesta etapa, o dataset será redimensionado para que as imagens possuam as dimensões de 299x299 pixels, tornando-as compatíveis com a entrada esperada pelo modelo Inception V3.\n",
    "\n",
    "Dada a alta demanda computacional deste modelo e a limitação de 4 GB de VRAM do sistema, será necessário reduzir o tamanho do *batch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFAR10Dataset(root=root, resize=(299, 299))\n",
    "train_dataloader = dataset.get_dataloader(dataset_type=\"train\", num_workers=num_workers, batch_size=50)\n",
    "val_dataloader = dataset.get_dataloader(dataset_type=\"val\", num_workers=num_workers, batch_size=50)\n",
    "test_dataloader = dataset.get_dataloader(dataset_type=\"val\", num_workers=num_workers, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08401498",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception = inception_v3(weights=Inception_V3_Weights.DEFAULT, progress=True)\n",
    "model_inception.aux_logits = False\n",
    "\n",
    "for param in model_inception.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "in_features_inception = model_inception.fc.in_features\n",
    "\n",
    "custom_classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features_inception, 128),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "\n",
    "# Pylance will complain about the data type, fc is Linear\n",
    "model_inception.fc = custom_classifier  # type: ignore\n",
    "\n",
    "light_inception_model = LightModel(model_inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\",\n",
    "    min_delta=0.001,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    callbacks=[early_stopping],\n",
    "    max_epochs=50,\n",
    "    accelerator=device_type,\n",
    "    devices=1,\n",
    "    # accumulate_grad_batches=2, # If were to reduce more batch size\n",
    ")\n",
    "print(\"\\n--- Training Inception with custom classifier ---\\n\")\n",
    "trainer.fit(\n",
    "    model=light_inception_model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e7f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Testing Inception with custom classifier ---\\n\")\n",
    "trainer.test(model=light_inception_model, dataloaders=test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
